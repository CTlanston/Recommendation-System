{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Construct credentials from service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'tche368-isom676-srvacct_srvacct.json')  # Update the file path as needed\n",
    "\n",
    "# Construct a BigQuery client object\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "# Revised and optimized query\n",
    "QUERY = \"\"\"\n",
    "WITH product_filter AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.products`\n",
    "    WHERE prod_category NOT IN (\"Gift Cards\", \"Other\", \"Front End Service\", \"Scanning Errors\", \"Customer Service-Misc\", \"Empties and Additionals\")\n",
    "),\n",
    "valid_transactions AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.transactions` a \n",
    "    join product_filter b on a.prod_id  = b.prod_id \n",
    "    WHERE trans_dt < \"2020-03-01\"\n",
    "    AND a.prod_id IN (SELECT prod_id FROM product_filter)\n",
    "        AND \n",
    "        -- Logic 1: Either sales_qty or sales_wgt is zero, but not both\n",
    "        ((sales_qty = 0 AND sales_wgt <> 0) OR (sales_qty <> 0 AND sales_wgt = 0))\n",
    "        AND \n",
    "        -- Logics 2 and 3 are parallel conditions\n",
    "        (\n",
    "            (prod_category NOT IN (\"Coupon\", \"returns\") AND (sales_qty > 0 OR sales_wgt > 0))\n",
    "            OR\n",
    "            (prod_category IN (\"Coupon\", \"returns\") AND (sales_qty < 0 OR sales_wgt < 0))\n",
    "        )\n",
    "    AND sales_amt >= 0\n",
    "),\n",
    "transactions_per_day AS (\n",
    "    SELECT cust_id, trans_dt, COUNT(DISTINCT trans_id) AS trans_per_day\n",
    "    FROM valid_transactions\n",
    "    GROUP BY cust_id, trans_dt\n",
    "    HAVING trans_per_day <= 10\n",
    "),\n",
    "eligible_custs AS (\n",
    "    SELECT v.cust_id\n",
    "    FROM valid_transactions v\n",
    "    JOIN transactions_per_day tpd ON v.cust_id = tpd.cust_id AND v.trans_dt = tpd.trans_dt\n",
    "    GROUP BY v.cust_id\n",
    "    HAVING COUNT(DISTINCT v.trans_id) >= 5\n",
    "    AND COUNT(DISTINCT v.trans_dt) >= 5\n",
    "    AND COUNT(v.trans_id) <= 20000\n",
    "),\n",
    "sampled_custs AS (\n",
    "    SELECT cust_id\n",
    "    FROM eligible_custs\n",
    "    WHERE MOD(ABS(FARM_FINGERPRINT(CAST(cust_id AS STRING))), 1000) < 1\n",
    ")\n",
    "SELECT tx.*\n",
    "FROM `valid_transactions` tx\n",
    "JOIN sampled_custs ON tx.cust_id = sampled_custs.cust_id\n",
    "WHERE tx.trans_dt < \"2020-03-01\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(QUERY)  # API request\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_transaction = query_job.to_dataframe()  # Waits for query to finish and converts it to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Construct credentials from service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'tche368-isom676-srvacct_srvacct.json')  # Update the file path as needed\n",
    "\n",
    "# Construct a BigQuery client object\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "# Revised and optimized query\n",
    "QUERY = \"\"\"\n",
    "WITH product_filter AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.products`\n",
    "    WHERE prod_category NOT IN (\"Gift Cards\", \"Other\", \"Front End Service\", \"Scanning Errors\", \"Customer Service-Misc\", \"Empties and Additionals\")\n",
    "),\n",
    "valid_transactions AS (\n",
    "    SELECT *\n",
    "    FROM `machine_learning.transactions` a \n",
    "    join product_filter b on a.prod_id  = b.prod_id \n",
    "    WHERE trans_dt < \"2020-03-01\"\n",
    "    AND a.prod_id IN (SELECT prod_id FROM product_filter)\n",
    "        AND \n",
    "        -- Logic 1: Either sales_qty or sales_wgt is zero, but not both\n",
    "        ((sales_qty = 0 AND sales_wgt <> 0) OR (sales_qty <> 0 AND sales_wgt = 0))\n",
    "        AND \n",
    "        -- Logics 2 and 3 are parallel conditions\n",
    "        (\n",
    "            (prod_category NOT IN (\"Coupon\", \"returns\") AND (sales_qty > 0 OR sales_wgt > 0))\n",
    "            OR\n",
    "            (prod_category IN (\"Coupon\", \"returns\") AND (sales_qty < 0 OR sales_wgt < 0))\n",
    "        )\n",
    "    AND sales_amt >= 0\n",
    "),\n",
    "transactions_per_day AS (\n",
    "    SELECT cust_id, trans_dt, COUNT(DISTINCT trans_id) AS trans_per_day\n",
    "    FROM valid_transactions\n",
    "    GROUP BY cust_id, trans_dt\n",
    "    HAVING trans_per_day <= 10\n",
    "),\n",
    "eligible_custs AS (\n",
    "    SELECT v.cust_id\n",
    "    FROM valid_transactions v\n",
    "    JOIN transactions_per_day tpd ON v.cust_id = tpd.cust_id AND v.trans_dt = tpd.trans_dt\n",
    "    GROUP BY v.cust_id\n",
    "    HAVING COUNT(DISTINCT v.trans_id) >= 5\n",
    "    AND COUNT(DISTINCT v.trans_dt) >= 5\n",
    "    AND COUNT(v.trans_id) <= 20000\n",
    "),\n",
    "sampled_custs AS (\n",
    "    SELECT cust_id\n",
    "    FROM eligible_custs\n",
    "    WHERE MOD(ABS(FARM_FINGERPRINT(CAST(cust_id AS STRING))), 200) < 1\n",
    ")\n",
    "SELECT tx.*\n",
    "FROM `valid_transactions` tx\n",
    "JOIN sampled_custs ON tx.cust_id = sampled_custs.cust_id\n",
    "WHERE tx.trans_dt < \"2020-03-01\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(QUERY)  # API request\n",
    "\n",
    "# Convert to DataFrame\n",
    "sample_transaction = query_job.to_dataframe()  # Waits for query to finish and converts it to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product and profit margin data\n",
    "product_profit_margin_df = pd.read_excel(\"C:/Users/ctlan/OneDrive/desktop/AI at Scale/HW/Product Category Profit Margin.xlsx\")\n",
    "\n",
    "# Merge with product_profit_margin to get profit margins\n",
    "merged_df = pd.merge(sample_transaction, product_profit_margin_df, on='prod_category', how='left')\n",
    "\n",
    "# Calculate profit for each transaction\n",
    "merged_df['profit'] = merged_df['sales_amt'] * merged_df['profit_margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loyal customer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is prepared with columns 'cust_id' and 'profit'\n",
    "\n",
    "# Mark loyal customers\n",
    "merged_df['is_loyal'] = merged_df['cust_id'].apply(lambda x: len(str(x)) == 10)\n",
    "\n",
    "# Calculate numbers of loyal and total customers\n",
    "total_customers = merged_df['cust_id'].nunique()\n",
    "loyal_customers = merged_df[merged_df['is_loyal']]['cust_id'].nunique()\n",
    "\n",
    "# Calculate total and loyal customers' profit\n",
    "total_profit = merged_df['profit'].sum()\n",
    "loyal_customers_profit = merged_df[merged_df['is_loyal']]['profit'].sum()\n",
    "\n",
    "# Calculate proportions\n",
    "loyal_customers_ratio = loyal_customers / total_customers\n",
    "loyal_customers_profit_ratio = loyal_customers_profit / total_profit\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'Metric': ['Loyal Customer Ratio', 'Loyal Customer Profit Ratio'],\n",
    "    'Value': [loyal_customers_ratio, loyal_customers_profit_ratio]\n",
    "})\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## customer pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adjustments for accurately identifying customers by category\n",
    "\n",
    "# Assuming merged_df is prepared with 'cust_id', 'prod_category', and 'sales_amt'\n",
    "\n",
    "# Identify all unique customers\n",
    "all_customers = merged_df['cust_id'].unique()\n",
    "\n",
    "# 1. Never use coupon\n",
    "# Find customers who have used coupons\n",
    "customers_used_coupons = merged_df[merged_df['prod_category'] == 'Coupons']['cust_id'].unique()\n",
    "# Find customers who have never used a coupon by excluding those who have\n",
    "customers_never_use_coupon = set(all_customers) - set(customers_used_coupons)\n",
    "# Calculate their profit\n",
    "profit_never_use_coupon = merged_df[(merged_df['cust_id'].isin(customers_never_use_coupon)) & (~merged_df['prod_category'].str.contains('Coupons'))]['sales_amt'].sum()\n",
    "\n",
    "# 2. Only buy One/Two/Three certain categories\n",
    "# Count unique categories per customer\n",
    "cust_category_counts = merged_df.groupby('cust_id')['prod_category'].nunique()\n",
    "# Customers who only buy from 1, 2, or 3 categories\n",
    "customers_one_two_three_categories = cust_category_counts[(cust_category_counts >= 1) & (cust_category_counts <= 3)].index\n",
    "# Calculate their profit\n",
    "profit_one_two_three_categories = merged_df[merged_df['cust_id'].isin(customers_one_two_three_categories)]['sales_amt'].sum()\n",
    "\n",
    "# 3. Buy everything (50+ categories)\n",
    "customers_buy_everything = cust_category_counts[cust_category_counts >= 50].index\n",
    "# Calculate their profit\n",
    "profit_buy_everything = merged_df[merged_df['cust_id'].isin(customers_buy_everything)]['sales_amt'].sum()\n",
    "\n",
    "# Total numbers and profits\n",
    "total_customers = len(all_customers)\n",
    "total_profit = merged_df['sales_amt'].sum()\n",
    "\n",
    "# Calculate proportions\n",
    "data = {\n",
    "    'Category': ['Never Use Coupon', 'Buy 1-3 Categories', 'Buy 50+ Categories'],\n",
    "    'Customer Count Proportion': [\n",
    "        len(customers_never_use_coupon) / total_customers,\n",
    "        len(customers_one_two_three_categories) / total_customers,\n",
    "        len(customers_buy_everything) / total_customers\n",
    "    ],\n",
    "    'Profit Proportion': [\n",
    "        profit_never_use_coupon / total_profit,\n",
    "        profit_one_two_three_categories / total_profit,\n",
    "        profit_buy_everything / total_profit\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = pd.DataFrame(data)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cherry picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设sample_transaction是已经加载的DataFrame，其中包含你提供的所有列。\n",
    "\n",
    "# 首先，我们将计算每个cust_id对于prod_category为Coupons的transaction占比\n",
    "# 1. 标记每个transaction是否为Coupons\n",
    "sample_transaction['is_coupon'] = (sample_transaction['prod_category'] == 'Coupons').astype(int)\n",
    "\n",
    "# 2. 对每个cust_id，计算总transaction数量和Coupons transaction的数量\n",
    "cust_transactions_summary = sample_transaction.groupby('cust_id').agg(\n",
    "    total_transactions=('trans_id', 'nunique'),  # 计算每个客户的唯一交易数\n",
    "    coupons_transactions=('is_coupon', 'sum')  # 计算Coupons的交易数\n",
    ")\n",
    "\n",
    "# 3. 计算每个cust_id的Coupons transaction占比\n",
    "cust_transactions_summary['coupons_ratio'] = cust_transactions_summary['coupons_transactions'] / cust_transactions_summary['total_transactions']\n",
    "\n",
    "# 4. 绘制分布直方图，纵坐标为顾客数的比例\n",
    "# 计算直方图\n",
    "counts, bins = np.histogram(cust_transactions_summary['coupons_ratio'], bins=np.arange(0, 1.05, 0.05))\n",
    "\n",
    "# 将计数转换为比例\n",
    "counts = counts / counts.sum()\n",
    "\n",
    "# 绘制直方图\n",
    "plt.bar(bins[:-1], counts, width=0.05, align='edge', edgecolor='black')\n",
    "plt.xlabel('Coupons Transaction Ratio')\n",
    "plt.ylabel('Proportion of Customers')\n",
    "plt.title('Distribution of Coupons Transaction Ratio per Customer')\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bar chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming merged_df is prepared with 'cust_id', 'prod_category', and 'sales_amt'\n",
    "\n",
    "# Calculate the number of unique categories purchased by each customer\n",
    "category_counts_per_customer = merged_df.groupby('cust_id')['prod_category'].nunique()\n",
    "\n",
    "# Calculate the total profit by customer\n",
    "profit_per_customer = merged_df.groupby('cust_id')['sales_amt'].sum()\n",
    "\n",
    "# Merge the two series into a DataFrame for easier analysis\n",
    "customer_analysis_df = pd.DataFrame({\n",
    "    'Category_Count': category_counts_per_customer,\n",
    "    'Total_Profit': profit_per_customer\n",
    "})\n",
    "\n",
    "# Define bins for the category count histogram\n",
    "bins_category_count = pd.cut(customer_analysis_df['Category_Count'], bins=5, labels=['1-5', '6-10', '11-15', '16-20', '21+'])\n",
    "\n",
    "# Plot histogram for the distribution of customers by category count\n",
    "plt.figure(figsize=(10, 6))\n",
    "bins_category_count.value_counts(normalize=True).sort_index().plot(kind='bar', color='red')\n",
    "plt.title('Customer Distribution by Number of Product Categories Purchased')\n",
    "plt.xlabel('Number of Product Categories')\n",
    "plt.ylabel('Proportion of Customers')\n",
    "plt.show()\n",
    "\n",
    "# For profit contribution, first assign each customer to a bin based on their category count\n",
    "customer_analysis_df['Category_Count_Bin'] = bins_category_count\n",
    "\n",
    "# Then, calculate the total profit for each bin\n",
    "profit_contribution_by_bin = customer_analysis_df.groupby('Category_Count_Bin')['Total_Profit'].sum()\n",
    "\n",
    "# Normalize the profit contribution by the total profit to get the proportion\n",
    "profit_contribution_by_bin_normalized = profit_contribution_by_bin / profit_contribution_by_bin.sum()\n",
    "\n",
    "# Plot histogram for the profit contribution by category count bin\n",
    "plt.figure(figsize=(10, 6))\n",
    "profit_contribution_by_bin_normalized.plot(kind='bar', color='red')\n",
    "plt.title('Profit Contribution by Number of Product Categories Purchased')\n",
    "plt.xlabel('Number of Product Categories')\n",
    "plt.ylabel('Proportion of Profit')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T -test check the distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the provided data\n",
    "data = {\n",
    "    'Category': ['Never Use Coupon', 'Buy 1-3 Categories', 'Buy 50+ Categories'],\n",
    "    'Customer Count Proportion 0.1%': [0.484003, 0.013765, 0.083333],\n",
    "    'Profit Proportion 0.1%': [0.146583, 0.003421, 0.451492],\n",
    "    'Customer Count Proportion 0.5%': [0.489452, 0.012824, 0.075960],\n",
    "    'Profit Proportion 0.5%': [0.142310, 0.002219, 0.443786]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# We need to assume a total number of customers to convert proportions to counts\n",
    "# Let's assume there are 1000 customers in each group for demonstration purposes\n",
    "n_customers = 1000\n",
    "\n",
    "# Calculate the observed counts of customers from the proportions\n",
    "df['Customer Count 0.1%'] = df['Customer Count Proportion 0.1%'] * n_customers\n",
    "df['Customer Count 0.5%'] = df['Customer Count Proportion 0.5%'] * n_customers\n",
    "\n",
    "# Extract the counts for the category 'Buy 50+ Categories' to perform the z-test\n",
    "count = df.loc[df['Category'] == 'Buy 50+ Categories', ['Customer Count 0.1%', 'Customer Count 0.5%']].values.flatten()\n",
    "nobs = [n_customers, n_customers]  # The number of observations in each sample\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "stat, pval = proportions_ztest(count, nobs)\n",
    "\n",
    "stat, pval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the z-test results\n",
    "ztest_results = []\n",
    "\n",
    "# There are three comparisons to make:\n",
    "# 1. Never Use Coupon\n",
    "# 2. Buy 1-3 Categories\n",
    "# 3. Buy 50+ Categories\n",
    "\n",
    "# Loop through each category to perform the z-tests\n",
    "for category in df['Category']:\n",
    "    # Extract the counts for the current category to perform the z-test\n",
    "    count = df.loc[df['Category'] == category, ['Customer Count 0.1%', 'Customer Count 0.5%']].values.flatten()\n",
    "    \n",
    "    # Perform the two-proportion z-test\n",
    "    stat, pval = proportions_ztest(count, nobs)\n",
    "    \n",
    "    # Append the results to our list\n",
    "    ztest_results.append((category, stat, pval))\n",
    "\n",
    "# Convert the z-test results to a DataFrame\n",
    "output_df = pd.DataFrame(ztest_results, columns=['Category', 'Z-Score', 'P-Value'])\n",
    "\n",
    "output_df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
